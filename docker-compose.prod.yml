# ============================================================
# Production Docker Compose
# 用法: docker compose -f docker-compose.prod.yml up -d
# ============================================================

services:
  # =============================================================
  # PostgreSQL
  # =============================================================
  postgres:
    image: registry.cn-shenzhen.aliyuncs.com/colovu/postgres:12.4
    container_name: kk_nl2sql_postgres
    restart: unless-stopped
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    volumes:
      - ./docker/volumes/postgres:/var/lib/postgresql/data
      - ./docker/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "1.0"
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # =============================================================
  # Redis
  # =============================================================
  redis:
    image: redis:7-alpine
    container_name: kk_nl2sql_redis
    restart: unless-stopped
    command: redis-server --maxmemory 256mb --maxmemory-policy allkeys-lru --appendonly yes
    volumes:
      - ./docker/volumes/redis:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "3"

  # =============================================================
  # etcd — Milvus 元数据
  # =============================================================
  etcd:
    container_name: kk_nl2sql_milvus_etcd
    image: quay.io/coreos/etcd:v3.5.25
    restart: unless-stopped
    environment:
      - ETCD_AUTO_COMPACTION_MODE=revision
      - ETCD_AUTO_COMPACTION_RETENTION=1000
      - ETCD_QUOTA_BACKEND_BYTES=4294967296
      - ETCD_SNAPSHOT_COUNT=50000
    volumes:
      - ./docker/volumes/milvus/etcd:/etcd
    command: etcd -advertise-client-urls=http://etcd:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 30s
      timeout: 20s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "3"

  # =============================================================
  # Milvus MinIO — 内部存储
  # =============================================================
  milvus-minio:
    container_name: kk_nl2sql_milvus_minio
    image: minio/minio:RELEASE.2024-12-18T13-15-44Z
    restart: unless-stopped
    environment:
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
    volumes:
      - ./docker/volumes/milvus/minio:/minio_data
    command: minio server /minio_data --console-address ":9011"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "3"

  # =============================================================
  # Milvus — 向量数据库
  # =============================================================
  milvus:
    container_name: kk_nl2sql_milvus
    image: milvusdb/milvus:v2.6.10
    restart: unless-stopped
    command: ["milvus", "run", "standalone"]
    security_opt:
      - seccomp:unconfined
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: milvus-minio:9000
      MQ_TYPE: woodpecker
    volumes:
      - ./docker/volumes/milvus/data:/var/lib/milvus
    depends_on:
      etcd:
        condition: service_healthy
      milvus-minio:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/healthz"]
      interval: 30s
      start_period: 90s
      timeout: 20s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "2.0"
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # =============================================================
  # MinIO (业务) — 文件存储
  # =============================================================
  minio:
    image: minio/minio:RELEASE.2025-04-22T22-12-26Z
    container_name: kk_nl2sql_minio
    restart: unless-stopped
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-admin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-admin123456}
    command: server /data --console-address ":9001"
    volumes:
      - ./docker/volumes/minio/data:/data
      - ./docker/volumes/minio/config:/root/.minio
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "3"

  # =============================================================
  # Backend — FastAPI (Gunicorn + Uvicorn workers)
  # =============================================================
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.prod
    container_name: kk_nl2sql_backend
    restart: unless-stopped
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=${POSTGRES_USER:-kk_nl2sql}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-kk_nl2sql_secret_2026}
      - POSTGRES_DB=${POSTGRES_DB:-kk_nl2sql}
      - REDIS_HOST=redis
      - MILVUS_HOST=milvus
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-admin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-admin123456}
      - MEMOS_API_URL=${MEMOS_API_URL:-https://memos.memtensor.cn/api/openmem/v1}
      - MEMOS_API_KEY=${MEMOS_API_KEY:-}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY:-}
      - QWEN_API_KEY=${QWEN_API_KEY:-}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY:-kk-nl2sql-aibot-jwt-secret-2026-change-in-production}
      - CORS_ORIGINS=${CORS_ORIGINS:-["http://localhost"]}
      - WORKERS=${WORKERS:-2}
      - TIMEOUT=120
      - LOG_LEVEL=info
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 20s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "2.0"
    logging:
      driver: json-file
      options:
        max-size: "20m"
        max-file: "5"

  # =============================================================
  # Celery Worker — 异步任务执行 (生产)
  # =============================================================
  celery-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile.prod
    container_name: kk_nl2sql_celery_worker
    command: celery -A app.tasks worker --loglevel=info --concurrency=2
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=${POSTGRES_USER:-kk_nl2sql}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-kk_nl2sql_secret_2026}
      - POSTGRES_DB=${POSTGRES_DB:-kk_nl2sql}
      - REDIS_HOST=redis
      - MILVUS_HOST=milvus
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-admin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-admin123456}
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/2
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "1.0"
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # =============================================================
  # Celery Beat — 定时任务调度 (生产)
  # =============================================================
  celery-beat:
    build:
      context: ./backend
      dockerfile: Dockerfile.prod
    container_name: kk_nl2sql_celery_beat
    command: celery -A app.tasks beat --loglevel=info --scheduler celery.beat:PersistentScheduler
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
    environment:
      - REDIS_HOST=redis
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/2
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: "0.25"
    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "3"

  # =============================================================
  # Frontend — React (Vite build → Nginx)
  # =============================================================
  frontend:
    build: ./frontend
    container_name: kk_nl2sql_frontend
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: "0.25"
    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "3"

  # =============================================================
  # Nginx — 反向代理 (生产配置)
  # =============================================================
  nginx:
    image: nginx:alpine
    container_name: kk_nl2sql_nginx
    restart: unless-stopped
    ports:
      - "${HTTP_PORT:-80}:80"
    volumes:
      - ./docker/nginx/nginx.prod.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      backend:
        condition: service_healthy
      frontend:
        condition: service_started
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: "0.5"
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "5"

networks:
  default:
    name: kk_nl2sql_network
